{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valerio Velardo Tutorial 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    LayerNormalization,\n",
    "    MultiHeadAttention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_position_encoding(num_positions, d_model):\n",
    "    \"\"\"\n",
    "    Compute positional encoding for a given position and dimension.\n",
    "\n",
    "    Parameters:\n",
    "        num_positions (int): Number of positions.\n",
    "        d_model (int): Dimension of the model.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Positional encoding for the given position and dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    angles = _get_angles(\n",
    "        np.arange(num_positions)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model,\n",
    "    )\n",
    "\n",
    "    # Apply sin to even indices in the array; 2i\n",
    "    sines = np.sin(angles[:, 0::2])\n",
    "\n",
    "    # Apply cos to odd indices in the array; 2i+1\n",
    "    cosines = np.cos(angles[:, 1::2])\n",
    "\n",
    "    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[np.newaxis, ...]  # (1, position, d_model)\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_angles(pos, i, d_model):\n",
    "    \"\"\"\n",
    "    Compute the angles for the positional encoding.\n",
    "\n",
    "    Parameters:\n",
    "        pos (np.ndarray): Positions.\n",
    "        i (np.ndarray): Indices.\n",
    "        d_model (int): Dimension of the model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Angles for the positional encoding.\n",
    "    \"\"\"\n",
    "    angle_dropout_rates = 1 / np.power(\n",
    "        10000, (2 * (i // 2)) / np.float32(d_model)\n",
    "    )\n",
    "    return pos * angle_dropout_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    The Transformer model architecture, consisting of an Encoder and Decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        d_feedforward,\n",
    "        input_vocab_size,\n",
    "        target_vocab_size,\n",
    "        max_num_positions_in_pe_encoder,\n",
    "        max_num_positions_in_pe_decoder,\n",
    "        dropout_rate=0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            num_layers (int): Number of layers in both Encoder and Decoder.\n",
    "            d_model (int): Dimension of the model.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_feedforward (int): Dimension of the feed forward network.\n",
    "            input_vocab_size (int): Size of the input vocabulary.\n",
    "            target_vocab_size (int): Size of the target vocabulary.\n",
    "            max_num_positions_in_pe_encoder (int): The maximum positions for input.\n",
    "            max_num_positions_in_pe_decoder (int): The maximum positions for\n",
    "                target.\n",
    "            dropout_rate (float): Dropout dropout_rate.\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(\n",
    "            num_layers,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            d_feedforward,\n",
    "            input_vocab_size,\n",
    "            max_num_positions_in_pe_encoder,\n",
    "            dropout_rate,\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            num_layers,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            d_feedforward,\n",
    "            target_vocab_size,\n",
    "            max_num_positions_in_pe_decoder,\n",
    "            dropout_rate,\n",
    "        )\n",
    "\n",
    "        self.final_layer = Dense(target_vocab_size)\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        input,\n",
    "        target,\n",
    "        training,\n",
    "        enc_padding_mask,\n",
    "        look_ahead_mask,\n",
    "        dec_padding_mask,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Process the input through the Transformer model.\n",
    "\n",
    "        Parameters:\n",
    "            input (Tensor): Input tensor to the Encoder.\n",
    "            target (Tensor): Target tensor for the Decoder.\n",
    "            training (bool): Whether the layer should behave in training mode.\n",
    "            enc_padding_mask (Tensor): Padding mask for the Encoder.\n",
    "            look_ahead_mask (Tensor): Look-ahead mask for the Decoder.\n",
    "            dec_padding_mask (Tensor): Padding mask for the Decoder.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The final output of the Transformer.\n",
    "            dict: Attention weights from the Decoder layers.\n",
    "        \"\"\"\n",
    "        enc_output = self.encoder(\n",
    "            input, training, enc_padding_mask\n",
    "        )  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        dec_output = self.decoder(\n",
    "            target, enc_output, training, look_ahead_mask, dec_padding_mask\n",
    "        )  # (batch_size, tar_seq_len, d_model)\n",
    "\n",
    "        logits = self.final_layer(\n",
    "            dec_output\n",
    "        )  # (batch_size, target_seq_len, target_vocab_size)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The Encoder of a Transformer model, consisting of multiple EncoderLayers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        d_feedforward,\n",
    "        input_vocab_size,\n",
    "        maximum_positions_in_pe,\n",
    "        dropout_rate=0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "            num_layers (int): Number of EncoderLayers.\n",
    "            d_model (int): Dimension of the model.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_feedforward (int): Dimension of the feed forward network.\n",
    "            input_vocab_size (int): Size of the input vocabulary.\n",
    "            maximum_positions_in_pe (int): The maximum sequence length that\n",
    "                this model might ever be used with.\n",
    "            dropout_rate (float): Dropout dropout_rate.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = sinusoidal_position_encoding(\n",
    "            maximum_positions_in_pe, d_model\n",
    "        )\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model, num_heads, d_feedforward, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Process the input through the Encoder.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "            training (bool): Whether the layer should behave in training mode.\n",
    "            mask (Tensor): Mask to be applied on attention weights.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output of the Encoder.\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        sliced_pos_encoding = self._get_sliced_positional_encoding(x)\n",
    "        x += sliced_pos_encoding\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    def _get_sliced_positional_encoding(self, x):\n",
    "        \"\"\"\n",
    "        Get a slice of the full positional encoding.\n",
    "\n",
    "        Patameters:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A slice of the full positional encoding.\n",
    "        \"\"\"\n",
    "        number_of_tokens = x.shape[1]\n",
    "        return self.pos_encoding[:, :number_of_tokens, :]\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    The Decoder of a Transformer model, consisting of multiple DecoderLayers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        d_feedforward,\n",
    "        target_vocab_size,\n",
    "        maximum_positions_in_pe,\n",
    "        dropout_rate=0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            num_layers (int): Number of DecoderLayers.\n",
    "            d_model (int): Dimension of the model.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_feedforward (int): Dimension of the feed forward network.\n",
    "            target_vocab_size (int): Size of the target vocabulary.\n",
    "            maximum_positions_in_pe (int): The maximum sequence length that\n",
    "                this model might ever be used with.\n",
    "            dropout_rate (float): Dropout dropout_rate.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = sinusoidal_position_encoding(\n",
    "            maximum_positions_in_pe, d_model\n",
    "        )\n",
    "\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model, num_heads, d_feedforward, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Process the input through the Decoder.\n",
    "\n",
    "        Parameters:\n",
    "            x (Tensor): Input tensor to the Decoder.\n",
    "            enc_output (Tensor): Output from the Encoder.\n",
    "            training (bool): Whether the layer should behave in training mode.\n",
    "            look_ahead_mask (Tensor): Mask for the first MultiHeadAttention layer.\n",
    "            padding_mask (Tensor): Mask for the second MultiHeadAttention layer.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output of the Decoder.\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        sliced_pos_encoding = self._get_sliced_positional_encoding(x)\n",
    "        x += sliced_pos_encoding\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](\n",
    "                x, enc_output, training, look_ahead_mask, padding_mask\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _get_sliced_positional_encoding(self, x):\n",
    "        \"\"\"\n",
    "        Get a slice of the full positional encoding.\n",
    "\n",
    "        Patameters:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: A slice of the full positional encoding.\n",
    "        \"\"\"\n",
    "        number_of_tokens = x.shape[1]\n",
    "        return self.pos_encoding[:, :number_of_tokens, :]\n",
    "\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer of a Transformer, consisting of MultiHeadAttention and\n",
    "    Feed Forward Neural Network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, d_feedforward, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            d_model (int): Dimension of the model.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_feedforward (int): Dimension of the feed forward network.\n",
    "            dropout_rate (float): Dropout dropout_rate.\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(key_dim=d_model, num_heads=num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(d_feedforward, activation=\"relu\"), Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        \"\"\"\n",
    "        Process the input through the Encoder layer.\n",
    "\n",
    "        Parameters:\n",
    "            x (Tensor): Input tensor.\n",
    "            training (bool): Whether the layer should behave in training mode.\n",
    "            mask (Tensor): Mask to be applied on attention weights.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output of the Encoder layer.\n",
    "        \"\"\"\n",
    "        attn_output = self.mha(x, x, x, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Decoder Layer of a Transformer, consisting of two MultiHeadAttention\n",
    "    layers and a Feed Forward Neural Network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, num_heads, d_feedforward, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            d_model (int): Dimension of the model.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_feedforward (int): Dimension of the feed forward network.\n",
    "            dropout_rate (float): Dropout dropout_rate.\n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.mha1 = MultiHeadAttention(key_dim=d_model, num_heads=num_heads)\n",
    "        self.mha2 = MultiHeadAttention(key_dim=d_model, num_heads=num_heads)\n",
    "\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(d_feedforward, activation=\"relu\"), Dense(d_model)]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "        self.dropout3 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        Process the input through the Decoder layer.\n",
    "\n",
    "        Parameters\n",
    "            x (Tensor): Input tensor to the Decoder layer.\n",
    "            enc_output (Tensor): Output from the Encoder.\n",
    "            training (bool): Whether the layer should behave in training mode.\n",
    "            look_ahead_mask (Tensor): Mask for the first MultiHeadAttention layer.\n",
    "            padding_mask (Tensor): Mask for the second MultiHeadAttention layer.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output of the Decoder layer.\n",
    "        \"\"\"\n",
    "        attn1 = self.mha1(x, x, x, attention_mask=look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2 = self.mha2(\n",
    "            out1, enc_output, enc_output, attention_mask=padding_mask\n",
    "        )\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_2 (Encoder)         multiple                  106496    \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  173184    \n",
      "                                                                 \n",
      " dense_17 (Dense)            multiple                  6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286180 (1.09 MB)\n",
      "Trainable params: 286180 (1.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define Transformer parameters\n",
    "num_layers = 2\n",
    "d_model = 64\n",
    "num_heads = 2\n",
    "d_feedforward = 128\n",
    "input_vocab_size = 100\n",
    "target_vocab_size = 100\n",
    "dropout_dropout_rate = 0.1\n",
    "pe_input = 10\n",
    "pe_target = 10\n",
    "\n",
    "# Instantiate the Transformer model\n",
    "transformer_model = Transformer(\n",
    "    num_layers,\n",
    "    d_model,\n",
    "    num_heads,\n",
    "    d_feedforward,\n",
    "    input_vocab_size,\n",
    "    target_vocab_size,\n",
    "    pe_input,\n",
    "    pe_target,\n",
    "    dropout_dropout_rate,\n",
    ")\n",
    "\n",
    "# Dummy input shapes for encoder and decoder\n",
    "dummy_inp = tf.random.uniform(\n",
    "    (1, 10), dtype=tf.int64, minval=0, maxval=input_vocab_size\n",
    ")\n",
    "dummy_tar = tf.random.uniform(\n",
    "    (1, 10), dtype=tf.int64, minval=0, maxval=target_vocab_size\n",
    ")\n",
    "\n",
    "# Build the model using dummy input\n",
    "transformer_model(\n",
    "    dummy_inp,\n",
    "    dummy_tar,\n",
    "    training=False,\n",
    "    enc_padding_mask=None,\n",
    "    look_ahead_mask=None,\n",
    "    dec_padding_mask=None,\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente-audio-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
